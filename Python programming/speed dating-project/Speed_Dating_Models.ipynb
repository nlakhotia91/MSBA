{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "path=\"/Users/nikitalakhotia/Desktop/msba docs/data programming/project/Speed Dating Data_statecodes.csv\"\n",
    "data=pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Difference between rating given by subject to partner and rating given by subject to oneself ##\n",
    "data[\"diff_attr\"]=data[\"attr\"]-data[\"attr3_1\"] ## rating to partner-rating to oneself\n",
    "data[\"diff_sinc\"]=data[\"sinc\"]-data[\"sinc3_1\"]\n",
    "data[\"diff_intel\"]=data[\"intel\"]-data[\"intel3_1\"]\n",
    "data[\"diff_fun\"]=data[\"fun\"]-data[\"fun3_1\"]\n",
    "data[\"diff_amb\"]=data[\"amb\"]-data[\"amb3_1\"]\n",
    "\n",
    "### if \"diff_attribute\" >0 than 1 else 0 i.e. partner's rating is higher than 1 else 0.\n",
    "\n",
    "def bin(col):\n",
    "    data.loc[data[col] > 0, col] = 1\n",
    "    data.loc[data[col] < 0, col] = 0\n",
    "    data.loc[data[col] == 0, col] = 0\n",
    "bin(\"diff_attr\")\n",
    "bin(\"diff_sinc\")\n",
    "bin(\"diff_intel\")\n",
    "bin(\"diff_fun\")\n",
    "bin(\"diff_amb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Filtering for male and female ##\n",
    "data_f=data[data[\"gender\"]==0]\n",
    "data_m=data[data[\"gender\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistics Regression taking into attributes (where subject rated the partner)\n",
    "\n",
    "1)The independent variables are the ratings that the subject assigned to the partner for various attributes such as Attractiveness, Ambition, Intelligence, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.502733\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    dec   No. Observations:                 3457\n",
      "Model:                          Logit   Df Residuals:                     3450\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Sat, 06 Aug 2016   Pseudo R-squ.:                  0.2386\n",
      "Time:                        22:33:02   Log-Likelihood:                -1737.9\n",
      "converged:                       True   LL-Null:                       -2282.7\n",
      "                                        LLR p-value:                3.881e-232\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -5.5508      0.274    -20.294      0.000        -6.087    -5.015\n",
      "attr           0.4062      0.029     13.871      0.000         0.349     0.464\n",
      "sinc          -0.0907      0.035     -2.602      0.009        -0.159    -0.022\n",
      "intel          0.1290      0.045      2.891      0.004         0.042     0.216\n",
      "fun            0.2745      0.033      8.205      0.000         0.209     0.340\n",
      "amb           -0.1727      0.034     -5.023      0.000        -0.240    -0.105\n",
      "shar           0.2763      0.027     10.374      0.000         0.224     0.328\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Logistic regression on females\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "y, X = dmatrices('dec ~ attr+sinc+intel+fun+amb+shar', data=data_f, return_type='dataframe')   \n",
    "model = sm.Logit(y, X)      # Fit model (find the intercept and slopes)\n",
    "result = model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.502307\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    dec   No. Observations:                 3583\n",
      "Model:                          Logit   Df Residuals:                     3576\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Sat, 06 Aug 2016   Pseudo R-squ.:                  0.2750\n",
      "Time:                        22:39:14   Log-Likelihood:                -1799.8\n",
      "converged:                       True   LL-Null:                       -2482.5\n",
      "                                        LLR p-value:                7.342e-292\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -5.2991      0.267    -19.853      0.000        -5.822    -4.776\n",
      "attr           0.6814      0.033     20.759      0.000         0.617     0.746\n",
      "sinc          -0.1605      0.037     -4.372      0.000        -0.232    -0.089\n",
      "intel         -0.0330      0.042     -0.778      0.437        -0.116     0.050\n",
      "fun            0.2606      0.034      7.645      0.000         0.194     0.327\n",
      "amb           -0.1529      0.034     -4.529      0.000        -0.219    -0.087\n",
      "shar           0.2708      0.026     10.405      0.000         0.220     0.322\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "## Logistic regression on males\n",
    "y, X = dmatrices('dec ~ attr+sinc+intel+fun+amb+shar', data=data_m, return_type='dataframe')   \n",
    "model = sm.Logit(y, X)      # Fit model (find the intercept and slopes)\n",
    "result = model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Insights:\n",
    "\n",
    "1) Males put more weight on physical attractivesness than female do.\n",
    "\n",
    "2) While females put more weight on intelligence as compared to males."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### taking interaction terms of attr and diff_attr ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.512620\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    dec   No. Observations:                 3702\n",
      "Model:                          Logit   Df Residuals:                     3686\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Sat, 06 Aug 2016   Pseudo R-squ.:                  0.2230\n",
      "Time:                        23:10:10   Log-Likelihood:                -1897.7\n",
      "converged:                       True   LL-Null:                       -2442.2\n",
      "                                        LLR p-value:                1.086e-222\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -3.4223      0.457     -7.486      0.000        -4.318    -2.526\n",
      "attr                 0.3381      0.046      7.272      0.000         0.247     0.429\n",
      "diff_attr           -0.0505      0.068     -0.739      0.460        -0.185     0.083\n",
      "attr:diff_attr       0.0295      0.010      3.077      0.002         0.011     0.048\n",
      "sinc                -0.1755      0.048     -3.683      0.000        -0.269    -0.082\n",
      "diff_sinc            0.2354      0.081      2.908      0.004         0.077     0.394\n",
      "sinc:diff_sinc      -0.0198      0.011     -1.873      0.061        -0.041     0.001\n",
      "intel                0.1174      0.062      1.891      0.059        -0.004     0.239\n",
      "diff_intel           0.1540      0.132      1.168      0.243        -0.104     0.412\n",
      "intel:diff_intel    -0.0178      0.016     -1.083      0.279        -0.050     0.014\n",
      "fun                  0.3804      0.046      8.230      0.000         0.290     0.471\n",
      "diff_fun             0.0074      0.075      0.097      0.922        -0.141     0.155\n",
      "fun:diff_fun        -0.0009      0.011     -0.087      0.930        -0.022     0.020\n",
      "amb                 -0.1494      0.040     -3.692      0.000        -0.229    -0.070\n",
      "diff_amb             0.0405      0.076      0.533      0.594        -0.108     0.189\n",
      "amb:diff_amb        -0.0010      0.010     -0.095      0.924        -0.021     0.019\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dec ~ attr*diff_attr+sinc*diff_sinc+intel*diff_intel+fun*diff_fun+\\\n",
    "                 amb*diff_amb', data=data_f, return_type='dataframe')   \n",
    "model = sm.Logit(y, X)      # Fit model (find the intercept and slopes)\n",
    "result = model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.502776\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    dec   No. Observations:                 3763\n",
      "Model:                          Logit   Df Residuals:                     3747\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Sat, 06 Aug 2016   Pseudo R-squ.:                  0.2738\n",
      "Time:                        23:09:46   Log-Likelihood:                -1891.9\n",
      "converged:                       True   LL-Null:                       -2605.4\n",
      "                                        LLR p-value:                2.579e-295\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -4.8600      0.428    -11.353      0.000        -5.699    -4.021\n",
      "attr                 0.6453      0.048     13.390      0.000         0.551     0.740\n",
      "diff_attr            0.2398      0.092      2.595      0.009         0.059     0.421\n",
      "attr:diff_attr      -0.0256      0.013     -2.035      0.042        -0.050    -0.001\n",
      "sinc                -0.2150      0.049     -4.423      0.000        -0.310    -0.120\n",
      "diff_sinc            0.1219      0.084      1.459      0.145        -0.042     0.286\n",
      "sinc:diff_sinc      -0.0065      0.011     -0.591      0.555        -0.028     0.015\n",
      "intel                0.1333      0.062      2.148      0.032         0.012     0.255\n",
      "diff_intel           0.1069      0.119      0.896      0.370        -0.127     0.341\n",
      "intel:diff_intel    -0.0455      0.016     -2.837      0.005        -0.077    -0.014\n",
      "fun                  0.2060      0.042      4.860      0.000         0.123     0.289\n",
      "diff_fun             0.4082      0.082      4.967      0.000         0.247     0.569\n",
      "fun:diff_fun        -0.0435      0.012     -3.654      0.000        -0.067    -0.020\n",
      "amb                 -0.0062      0.041     -0.151      0.880        -0.086     0.074\n",
      "diff_amb             0.0954      0.067      1.419      0.156        -0.036     0.227\n",
      "amb:diff_amb        -0.0268      0.010     -2.801      0.005        -0.046    -0.008\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dec ~ attr*diff_attr+sinc*diff_sinc+intel*diff_intel+fun*diff_fun+\\\n",
    "                 amb*diff_amb', data=data_m, return_type='dataframe')   \n",
    "model = sm.Logit(y, X)      # Fit model (find the intercept and slopes)\n",
    "result = model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) For ambition, the interaction term is insignificant for females but is significantly negative for males.  In other words, men strictly prefer women with their own level of ambition to women more ambitious than they are. \n",
    "\n",
    "2) The results on intelligence are qualitatively similar to those on ambition\n",
    "\n",
    "Hence, we demonstrate that on average men do not value women’s intel- ligence or ambition when it exceeds their own; moreover, a man is less likely to select a woman whom he perceives to be more ambi- tious than he is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Look at the importance of similarity ###\n",
    "data_s1=data[[\"iid\",\"pid\",\"field_cd\",\"country\"]]\n",
    "data_s2=data[[\"iid\",\"pid\",\"field_cd\",\"country\"]]\n",
    "data_s=pd.merge(data_s1, data_s2, how=\"inner\",left_on=[\"iid\",\"pid\"], right_on=[\"pid\",\"iid\"], suffixes=[\"_dater\",\"_partner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## variable -> if subject has same race as partner \n",
    "data_s[\"field_same\"]=0\n",
    "data_s.loc[data_s[\"field_cd_dater\"]== data_s[\"field_cd_partner\"], \"field_same\"] = 1\n",
    "\n",
    "data_s[\"region_same\"]=0\n",
    "data_s.loc[data_s[\"country_dater\"]== data_s[\"country_partner\"], \"region_same\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_s_drop=data_s.drop(data_s.columns[[2,3,4,5,6,7]], axis=1)\n",
    "data_final=pd.merge(data, data_s_drop, how=\"left\", left_on=[\"iid\",\"pid\"], right_on=[\"iid_dater\", \"pid_dater\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Filtering for male and female ##\n",
    "data_f=data_final[data_final[\"gender\"]==0]\n",
    "data_m=data_final[data_final[\"gender\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654935\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    dec   No. Observations:                 4184\n",
      "Model:                          Logit   Df Residuals:                     4180\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sun, 07 Aug 2016   Pseudo R-squ.:                0.002360\n",
      "Time:                        01:50:43   Log-Likelihood:                -2740.2\n",
      "converged:                       True   LL-Null:                       -2746.7\n",
      "                                        LLR p-value:                  0.004712\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      -0.6680      0.052    -12.750      0.000        -0.771    -0.565\n",
      "samerace        0.1963      0.066      2.985      0.003         0.067     0.325\n",
      "field_same      0.1892      0.099      1.906      0.057        -0.005     0.384\n",
      "region_same     0.0304      0.065      0.469      0.639        -0.096     0.157\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dec ~ samerace+field_same+region_same', data=data_f, return_type='dataframe')   \n",
    "model = sm.Logit(y, X)      # Fit model (find the intercept and slopes)\n",
    "result = model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.688579\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    dec   No. Observations:                 4184\n",
      "Model:                          Logit   Df Residuals:                     4180\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sun, 07 Aug 2016   Pseudo R-squ.:                0.004746\n",
      "Time:                        01:50:51   Log-Likelihood:                -2881.0\n",
      "converged:                       True   LL-Null:                       -2894.8\n",
      "                                        LLR p-value:                 4.670e-06\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      -0.2352      0.050     -4.683      0.000        -0.334    -0.137\n",
      "samerace       -0.0161      0.064     -0.253      0.800        -0.141     0.109\n",
      "field_same      0.4153      0.098      4.241      0.000         0.223     0.607\n",
      "region_same     0.1881      0.062      3.012      0.003         0.066     0.311\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dec ~ samerace+field_same+region_same', data=data_m, return_type='dataframe')   \n",
    "model = sm.Logit(y, X)      # Fit model (find the intercept and slopes)\n",
    "result = model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) women exhibit strong preference for partners of their own race, while men do not.\n",
    "Women strongly discriminate on the basis of race. Men, on the other hand, do not exhibit a significant racial preference.\n",
    "\n",
    "2)both men and women prefer partners from the same region of the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.512149\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    dec   No. Observations:                 3702\n",
      "Model:                          Logit   Df Residuals:                     3683\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Sun, 07 Aug 2016   Pseudo R-squ.:                  0.2237\n",
      "Time:                        01:58:32   Log-Likelihood:                -1896.0\n",
      "converged:                       True   LL-Null:                       -2442.2\n",
      "                                        LLR p-value:                1.151e-220\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -5.7442      0.333    -17.239      0.000        -6.397    -5.091\n",
      "attr                 0.4117      0.036     11.531      0.000         0.342     0.482\n",
      "diff_attr            2.1227      0.561      3.784      0.000         1.023     3.222\n",
      "attr:diff_attr      -0.2228      0.074     -3.023      0.002        -0.367    -0.078\n",
      "sinc                -0.0356      0.037     -0.959      0.338        -0.108     0.037\n",
      "diff_sinc            1.9506      0.674      2.893      0.004         0.629     3.272\n",
      "sinc:diff_sinc      -0.2038      0.079     -2.578      0.010        -0.359    -0.049\n",
      "intel                0.1536      0.049      3.147      0.002         0.058     0.249\n",
      "diff_intel          -0.1656      0.904     -0.183      0.855        -1.937     1.606\n",
      "intel:diff_intel     0.0073      0.103      0.071      0.944        -0.194     0.209\n",
      "fun                  0.3984      0.035     11.352      0.000         0.330     0.467\n",
      "diff_fun             1.8127      0.660      2.747      0.006         0.519     3.106\n",
      "fun:diff_fun        -0.2127      0.082     -2.606      0.009        -0.373    -0.053\n",
      "amb                 -0.1403      0.039     -3.588      0.000        -0.217    -0.064\n",
      "diff_amb            -0.0929      0.524     -0.177      0.859        -1.120     0.935\n",
      "amb:diff_amb         0.0244      0.066      0.369      0.712        -0.105     0.154\n",
      "samerace             0.0760      0.082      0.925      0.355        -0.085     0.237\n",
      "field_same           0.0929      0.120      0.772      0.440        -0.143     0.329\n",
      "region_same         -0.1527      0.080     -1.902      0.057        -0.310     0.005\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dec ~ attr*diff_attr+sinc*diff_sinc+intel*diff_intel+fun*diff_fun+\\\n",
    "                 amb*diff_amb+samerace+field_same+region_same', data=data_f, return_type='dataframe')   \n",
    "model = sm.Logit(y, X)      # Fit model (find the intercept and slopes)\n",
    "result = model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503359\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    dec   No. Observations:                 3753\n",
      "Model:                          Logit   Df Residuals:                     3734\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Sun, 07 Aug 2016   Pseudo R-squ.:                  0.2730\n",
      "Time:                        01:58:32   Log-Likelihood:                -1889.1\n",
      "converged:                       True   LL-Null:                       -2598.7\n",
      "                                        LLR p-value:                1.132e-290\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -6.8982      0.367    -18.800      0.000        -7.617    -6.179\n",
      "attr                 0.7602      0.045     17.058      0.000         0.673     0.848\n",
      "diff_attr            1.4934      0.544      2.747      0.006         0.428     2.559\n",
      "attr:diff_attr      -0.1958      0.074     -2.637      0.008        -0.341    -0.050\n",
      "sinc                -0.1392      0.040     -3.441      0.001        -0.218    -0.060\n",
      "diff_sinc            0.8777      0.717      1.224      0.221        -0.528     2.283\n",
      "sinc:diff_sinc      -0.0808      0.086     -0.942      0.346        -0.249     0.087\n",
      "intel                0.0570      0.046      1.245      0.213        -0.033     0.147\n",
      "diff_intel           2.4536      0.946      2.595      0.009         0.600     4.307\n",
      "intel:diff_intel    -0.3374      0.110     -3.078      0.002        -0.552    -0.123\n",
      "fun                  0.4186      0.038     11.026      0.000         0.344     0.493\n",
      "diff_fun             3.3167      0.507      6.547      0.000         2.324     4.310\n",
      "fun:diff_fun        -0.4111      0.067     -6.102      0.000        -0.543    -0.279\n",
      "amb                 -0.0246      0.038     -0.649      0.516        -0.099     0.050\n",
      "diff_amb            -0.0682      0.497     -0.137      0.891        -1.042     0.906\n",
      "amb:diff_amb        -0.0267      0.067     -0.400      0.689        -0.158     0.104\n",
      "samerace            -0.0583      0.083     -0.705      0.481        -0.221     0.104\n",
      "field_same           0.2254      0.128      1.756      0.079        -0.026     0.477\n",
      "region_same         -0.1384      0.082     -1.692      0.091        -0.299     0.022\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dec ~ attr*diff_attr+sinc*diff_sinc+intel*diff_intel+fun*diff_fun+\\\n",
    "                 amb*diff_amb+samerace+field_same+region_same', data=data_m, return_type='dataframe')   \n",
    "model = sm.Logit(y, X)      # Fit model (find the intercept and slopes)\n",
    "result = model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering K means ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x125256390>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1130cb0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "model = KMeans(n_clusters=5, random_state=1)\n",
    "data_cluster=data_final[[\"attr\",\"diff_attr\",\"sinc\",\"diff_sinc\",\"intel\",\"diff_intel\",\"fun\",\"diff_fun\",\\\n",
    "                         \"amb\",\"diff_amb\",\"samerace\",\"field_same\",\"region_same\", \"gender\",\"dec\"]]\n",
    "data_f_no_na=data_cluster.fillna(0)\n",
    "X=data_f_no_na.values\n",
    "model.fit(X)\n",
    "scatter(X[:,1], X[:,4], c=model.labels_, cmap='gist_ncar')\n",
    "scatter(model.cluster_centers_[:,13], model.cluster_centers_[:,14], marker=\"x\", s=200, linewidths=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98172820708\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('dec ~ attr*diff_attr+sinc*diff_sinc+intel*diff_intel+fun*diff_fun+\\\n",
    "                 amb*diff_amb+samerace+field_same+region_same', data=data_m, return_type='dataframe')   \n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "from sklearn import tree ## Set up classifier\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "result = model.fit(X_train, y_train) ##fit the data\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "prediction_train = model.predict(X_train)\n",
    "print metrics.accuracy_score(y_train, prediction_train) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693605683837\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, prediction) ## accuracy on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is far worse than the 92% accuracy we expected from the training set. Clearly, we are **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to avoid overfitting is to ensure that trees never become too deep, via the _max\\_depth_ argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732394366197\n"
     ]
    }
   ],
   "source": [
    "model2 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "result = model2.fit(X_train, y_train)\n",
    "\n",
    "prediction_train = model2.predict(X_train)\n",
    "print metrics.accuracy_score(y_train, prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745115452931\n"
     ]
    }
   ],
   "source": [
    "prediction = model2.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "import pydotplus\n",
    "from IPython.display import Image \n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model2, out_file=dot_data, feature_names=X.columns.values)\n",
    "#pydotplus.graph_from_dot_data(dot_data.getvalue()).write_png('/Users/nikitalakhotia/Desktop/trial.png')\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
